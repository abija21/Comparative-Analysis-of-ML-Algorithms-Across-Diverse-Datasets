{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce075e5-98df-480e-9e2c-4ef3b00fe139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8ac9bd-af3a-4826-95f8-ca165620376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical attributes\n",
    "def one_hot_encode(df):\n",
    "    return pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cc4d68-cc1d-4c8d-9a94-657f02708bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Loan Dataset\n",
    "data = pd.read_csv(\"parkinsons.csv\")\n",
    "df_encoded = one_hot_encode(data)\n",
    "X = df_encoded.drop('Diagnosis', axis=1).values\n",
    "y = df_encoded['Diagnosis'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1027391-e119-42a3-87c6-777b70726094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute Euclidean distance\n",
    "def euclidean_distance(instance1, instance2):\n",
    "    # print(instance1, instance2)\n",
    "    sq_difference = (instance1 - instance2) ** 2\n",
    "    sum_of_sq_difference = np.sum(sq_difference)\n",
    "    euclidean_distance = np.sqrt(sum_of_sq_difference)\n",
    "    # print(euclidean_distance)\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88775204-db15-4a94-afae-1e650214fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get nearest neighbors\n",
    "def get_neighbors(train, test_row, k):\n",
    "    distances = []\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row[:-1])\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = []\n",
    "    for i in range(k):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9399fdeb-2a54-42f0-a8af-73924aa68c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the class\n",
    "def predict_classification(train, test_row, k):\n",
    "    neighbors = get_neighbors(train, test_row, k)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dac6901-2a46-4d2d-b18c-26a55155f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split function\n",
    "def stratified_kfold(X, y, k):\n",
    "    from collections import defaultdict\n",
    "    folds = [([], []) for _ in range(k)]\n",
    "    label_indices = defaultdict(list)\n",
    "\n",
    "    # Organize indices by label\n",
    "    for idx, label in enumerate(y):\n",
    "        label_indices[label].append(idx)\n",
    "\n",
    "    # Distribute indices of each label roughly evenly across the folds\n",
    "    for indices in label_indices.values():\n",
    "        np.random.shuffle(indices)\n",
    "        for fold_idx, idx in enumerate(indices):\n",
    "            # folds[fold_idx % k][0].append(X.iloc[idx])  # for parkinson & titanic\n",
    "            # folds[fold_idx % k][1].append(y.iloc[idx])\n",
    "            folds[fold_idx % k][0].append(X[idx])  # for loan dataset\n",
    "            folds[fold_idx % k][1].append(y[idx])\n",
    "    # Shuffle each fold to mix labels\n",
    "    for fold in folds:\n",
    "        combined = list(zip(*fold))\n",
    "        np.random.shuffle(combined)\n",
    "        fold[0][:], fold[1][:] = zip(*combined)\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0cebcd3-0d7b-48b3-a221-aff0ae615023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model over a range of k values\n",
    "k_values = range(1, 52, 5)\n",
    "# average_training_accuracies = []\n",
    "average_testing_accuracies = []\n",
    "# average_training_f1_scores = []\n",
    "average_testing_f1_scores = []\n",
    "accuracy_std_devs = []\n",
    "f1_score_std_devs = []\n",
    "\n",
    "# Perform manual stratified K-fold\n",
    "folds = stratified_kfold(X, y, 10)\n",
    "\n",
    "for k in k_values:\n",
    "    # training_accuracies = []\n",
    "    testing_accuracies = []\n",
    "    # training_f1_scores = []\n",
    "    testing_f1_scores = []\n",
    "\n",
    "    for i in range(10):\n",
    "        X_test, y_test = folds[i]\n",
    "        X_train = [item for idx, fold in enumerate(folds) if idx != i for item in fold[0]]\n",
    "        y_train = [item for idx, fold in enumerate(folds) if idx != i for item in fold[1]]\n",
    "\n",
    "        # Normalize the features\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Prepare data for k-NN (add labels back to features for training)\n",
    "        train_data = np.column_stack((X_train_scaled, y_train))\n",
    "        test_data = np.column_stack((X_test_scaled, y_test))\n",
    "\n",
    "        # Make predictions for each test instance and evaluate\n",
    "        y_pred_train = [predict_classification(train_data, row[:-1], k) for row in train_data]\n",
    "        y_pred_test = [predict_classification(train_data, row[:-1], k) for row in test_data]\n",
    "\n",
    "        # training_accuracies.append(accuracy_score(y_train, y_pred_train))\n",
    "        testing_accuracies.append(accuracy_score(y_test, y_pred_test))\n",
    "        # training_f1_scores.append(f1_score(y_train, y_pred_train, average='macro'))\n",
    "        testing_f1_scores.append(f1_score(y_test, y_pred_test, average='macro'))\n",
    "\n",
    "    # Storing average scores\n",
    "    # average_training_accuracies.append(np.mean(training_accuracies))\n",
    "    average_testing_accuracies.append(np.mean(testing_accuracies))\n",
    "    # average_training_f1_scores.append(np.mean(training_f1_scores))\n",
    "    average_testing_f1_scores.append(np.mean(testing_f1_scores))\n",
    "\n",
    "    # Calculate and append the standard deviation for the current k\n",
    "    accuracy_std_devs.append(np.std(testing_accuracies))\n",
    "    f1_score_std_devs.append(np.std(testing_f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3da94-931a-4eb3-8499-1194c38fadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary Statistics:\")\n",
    "for k, accuracy, f1 in zip(k_values, average_testing_accuracies, average_testing_f1_scores):\n",
    "    print(f\"k: {k}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcccaaf-9bf3-44e3-aba2-8c3043e8440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "# plt.plot(k_values, average_training_accuracies, label='Training Accuracy', marker='o', color='blue')\n",
    "plt.errorbar(k_values, average_testing_accuracies, yerr=accuracy_std_devs, label='Accuracy', marker='s', color='grey',\n",
    "             linestyle='-', fmt='o', capsize=5)\n",
    "plt.title('k-NN Accuracy for Varying k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb627d-92b0-4ba5-b926-4649bdfa197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting F1 Score\n",
    "plt.figure(figsize=(10, 5))\n",
    "# plt.plot(k_values, average_training_f1_scores, label='Training F1 Score', marker='o', color='blue')\n",
    "plt.errorbar(k_values, average_testing_f1_scores, yerr=f1_score_std_devs, label='F1 Score', marker='s', color='grey',\n",
    "             linestyle='-', fmt='o', capsize=5)\n",
    "plt.title('k-NN F1 Score for Varying k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
